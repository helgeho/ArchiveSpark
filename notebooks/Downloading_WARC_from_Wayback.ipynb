{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading a web archive dataset as WARC/CDX from the Wayback Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.archive.webservices.archivespark._\n",
    "import org.archive.webservices.archivespark.functions._\n",
    "import org.archive.webservices.archivespark.specific.warc._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset from the Wayback Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ArchiveSpark provides a [Data Specification (DataSpec)](https://github.com/helgeho/ArchiveSpark/blob/master/docs/DataSpecs.md) to load records remotely from the Wayback Machine with metadata fetched from [CDX Server](https://github.com/internetarchive/wayback/tree/master/wayback-cdx-server). For more details about this and other [DataSpecs](https://github.com/helgeho/ArchiveSpark/blob/master/docs/DataSpecs.md) please read the [docs](https://github.com/helgeho/ArchiveSpark/blob/master/docs/README.md).\n",
    "\n",
    "The following example loads all archived resources under the domain `helgeholzmann.de` (`matchPrefix = true`) between May and June 2019, with 5 blocks per page for max. 50 pages (please read [the CDX server documentation](https://github.com/internetarchive/wayback/tree/master/wayback-cdx-server) for more information on these parameters):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "val records = ArchiveSpark.load(WarcSpec.fromWayback(\"helgeholzmann.de\", matchPrefix = true, from = 201905, to = 201906, blocksPerPage = 5, pages = 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peeking at the first record as JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual the records in this dataset can be printed as JSON and all common [operations](https://github.com/helgeho/ArchiveSpark/blob/master/docs/Operations.md) as well as [Enrichment Functions](https://github.com/helgeho/ArchiveSpark/blob/master/docs/EnrichFuncs.md) can be applied as shown in [other recipes](https://github.com/helgeho/ArchiveSpark/blob/master/docs/Recipes.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"record\" : {\n",
       "        \"redirectUrl\" : \"-\",\n",
       "        \"timestamp\" : \"20190528152652\",\n",
       "        \"digest\" : \"HCHVDRUSN7WDGNZFJES2Y4KZADQ6KINN\",\n",
       "        \"originalUrl\" : \"https://www.helgeholzmann.de/\",\n",
       "        \"surtUrl\" : \"de,helgeholzmann)/\",\n",
       "        \"mime\" : \"warc/revisit\",\n",
       "        \"compressedSize\" : 771,\n",
       "        \"meta\" : \"-\",\n",
       "        \"status\" : -1\n",
       "    }\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.peekJson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This revisit record that marks a duplicate in the Wayback Machine will be stored as the original `text/html` resource when downloaded locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving as WARC / CDX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the records as local *.warc.gz and *.cdx.gz files (by adding the `.gz` extension to the path, the output will be compressed using GZip):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.saveAsWarc(\"/data/helgeholzmann-de.warc.gz\", WarcFileMeta(publisher = \"Helge Holzmann\"), generateCdx = true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Loading from WARC / CDX\n",
    "\n",
    "Now, with the dataset available in local WARC / CDX files, we can load it from there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val records = ArchiveSpark.load(WarcSpec.fromFilesWithCdx(\"/data/helgeholzmann-de.warc.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"record\" : {\n",
       "        \"redirectUrl\" : \"-\",\n",
       "        \"timestamp\" : \"20190528152652\",\n",
       "        \"digest\" : \"sha1:HCHVDRUSN7WDGNZFJES2Y4KZADQ6KINN\",\n",
       "        \"originalUrl\" : \"https://www.helgeholzmann.de/\",\n",
       "        \"surtUrl\" : \"de,helgeholzmann)/\",\n",
       "        \"mime\" : \"text/html\",\n",
       "        \"compressedSize\" : 2087,\n",
       "        \"meta\" : \"-\",\n",
       "        \"status\" : 200\n",
       "    }\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.peekJson"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArchiveSpark",
   "language": "",
   "name": "archivespark"
  },
  "language_info": {
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
